import tokenizers

MAX_LEN=128
TRAIN_BATCH_SIZE=32
VALID_BATCH_SIZE=16
EPOCHS=10
BERT_PATH='../input/bert_base_uncased/'
MODEL_PATH='model.bin'
TRANING_FILE='../input/train.csv'
TOKENIZER=tokenizers.BertWordPieceTokenizer(
    os.path.join(BERT_PATH, 'vocab.txt'), 
    lowercase=True
)


